digraph {
	graph [size="90.3,90.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	125396873854352 [label="
 ()" fillcolor=darkolivegreen1]
	125396891717728 [label=MeanBackward0]
	125396884343296 -> 125396891717728
	125396884343296 [label=SqueezeBackward1]
	125396879102480 -> 125396884343296
	125396879102480 [label=ConvolutionBackward0]
	125396905345328 -> 125396879102480
	125396905345328 [label=EluBackward0]
	125396903871392 -> 125396905345328
	125396903871392 [label=ConvolutionBackward0]
	125396896465872 -> 125396903871392
	125396896465872 [label=EluBackward0]
	125396891041600 -> 125396896465872
	125396891041600 [label=ConvolutionBackward0]
	125396878650016 -> 125396891041600
	125396878650016 [label=ReluBackward0]
	125396878649872 -> 125396878650016
	125396878649872 [label=NativeBatchNormBackward0]
	125396904160768 -> 125396878649872
	125396904160768 [label=ConvolutionBackward0]
	125396873865072 -> 125396904160768
	125396873865072 [label=ReluBackward0]
	125396873865216 -> 125396873865072
	125396873865216 [label=NativeBatchNormBackward0]
	125396873865312 -> 125396873865216
	125396873865312 [label=ConvolutionBackward0]
	125396873865456 -> 125396873865312
	125396873865456 [label=ReluBackward0]
	125396873865600 -> 125396873865456
	125396873865600 [label=NativeBatchNormBackward0]
	125396873865696 -> 125396873865600
	125396873865696 [label=ConvolutionBackward0]
	125396873857248 -> 125396873865696
	125396873857248 [label=PermuteBackward0]
	125396873866032 -> 125396873857248
	125396873866032 [label=SumBackward1]
	125396873855040 -> 125396873866032
	125396873855040 [label=MulBackward0]
	125396892536688 -> 125396873855040
	125396892536688 [label=IndexBackward0]
	125396873866272 -> 125396892536688
	125396873866272 [label=SliceBackward0]
	125396884199776 -> 125396873866272
	125396884199776 [label=PermuteBackward0]
	125396873866368 -> 125396884199776
	125396873866368 [label=ReluBackward0]
	125396873866512 -> 125396873866368
	125396873866512 [label=NativeBatchNormBackward0]
	125396873866656 -> 125396873866512
	125396873866656 [label=ConvolutionBackward0]
	125396873866944 -> 125396873866656
	125396873866944 [label=ReluBackward0]
	125396873867040 -> 125396873866944
	125396873867040 [label=NativeBatchNormBackward0]
	125396873867088 -> 125396873867040
	125396873867088 [label=ConvolutionBackward0]
	125396873867376 -> 125396873867088
	125396873867376 [label=PermuteBackward0]
	125396873867568 -> 125396873867376
	125396873867568 [label=CatBackward0]
	125396873867616 -> 125396873867568
	125396873867616 [label=PermuteBackward0]
	125396873867808 -> 125396873867616
	125396873867808 [label=MaxBackward0]
	125396873867856 -> 125396873867808
	125396873867856 [label=ReluBackward0]
	125396873868000 -> 125396873867856
	125396873868000 [label=NativeBatchNormBackward0]
	125396873864688 -> 125396873868000
	125396873864688 [label=ConvolutionBackward0]
	125396873868480 -> 125396873864688
	125396873868480 [label=ReluBackward0]
	125396873868672 -> 125396873868480
	125396873868672 [label=NativeBatchNormBackward0]
	125396873868720 -> 125396873868672
	125396873868720 [label=ConvolutionBackward0]
	125396873869008 -> 125396873868720
	125396873869008 [label=ReluBackward0]
	125396873869200 -> 125396873869008
	125396873869200 [label=NativeBatchNormBackward0]
	125396873869248 -> 125396873869200
	125396873869248 [label=ConvolutionBackward0]
	125396873869536 -> 125396873869248
	125396873735824 [label="point_base_model.sa1.mlp_convs.0.weight
 (32, 18, 1, 1)" fillcolor=lightblue]
	125396873735824 -> 125396873869536
	125396873869536 [label=AccumulateGrad]
	125396873869488 -> 125396873869248
	125396873727584 [label="point_base_model.sa1.mlp_convs.0.bias
 (32)" fillcolor=lightblue]
	125396873727584 -> 125396873869488
	125396873869488 [label=AccumulateGrad]
	125396873869104 -> 125396873869200
	125397160409632 [label="point_base_model.sa1.mlp_bns.0.weight
 (32)" fillcolor=lightblue]
	125397160409632 -> 125396873869104
	125396873869104 [label=AccumulateGrad]
	125396873869344 -> 125396873869200
	125397160409552 [label="point_base_model.sa1.mlp_bns.0.bias
 (32)" fillcolor=lightblue]
	125397160409552 -> 125396873869344
	125396873869344 [label=AccumulateGrad]
	125396873868960 -> 125396873868720
	125397160409232 [label="point_base_model.sa1.mlp_convs.1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	125397160409232 -> 125396873868960
	125396873868960 [label=AccumulateGrad]
	125396873868912 -> 125396873868720
	125397160409152 [label="point_base_model.sa1.mlp_convs.1.bias
 (32)" fillcolor=lightblue]
	125397160409152 -> 125396873868912
	125396873868912 [label=AccumulateGrad]
	125396873868576 -> 125396873868672
	125397160408912 [label="point_base_model.sa1.mlp_bns.1.weight
 (32)" fillcolor=lightblue]
	125397160408912 -> 125396873868576
	125396873868576 [label=AccumulateGrad]
	125396873868816 -> 125396873868672
	125397160408832 [label="point_base_model.sa1.mlp_bns.1.bias
 (32)" fillcolor=lightblue]
	125397160408832 -> 125396873868816
	125396873868816 [label=AccumulateGrad]
	125396873868432 -> 125396873864688
	125397160408352 [label="point_base_model.sa1.mlp_convs.2.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	125397160408352 -> 125396873868432
	125396873868432 [label=AccumulateGrad]
	125396873868384 -> 125396873864688
	125397160407952 [label="point_base_model.sa1.mlp_convs.2.bias
 (64)" fillcolor=lightblue]
	125397160407952 -> 125396873868384
	125396873868384 [label=AccumulateGrad]
	125396873864832 -> 125396873868000
	125397160407872 [label="point_base_model.sa1.mlp_bns.2.weight
 (64)" fillcolor=lightblue]
	125397160407872 -> 125396873864832
	125396873864832 [label=AccumulateGrad]
	125396873868240 -> 125396873868000
	125397160407792 [label="point_base_model.sa1.mlp_bns.2.bias
 (64)" fillcolor=lightblue]
	125397160407792 -> 125396873868240
	125396873868240 [label=AccumulateGrad]
	125396873867472 -> 125396873867568
	125396873867472 [label=SumBackward1]
	125396873867952 -> 125396873867472
	125396873867952 [label=MulBackward0]
	125396873868864 -> 125396873867952
	125396873868864 [label=IndexBackward0]
	125396873868528 -> 125396873868864
	125396873868528 [label=SliceBackward0]
	125396873869152 -> 125396873868528
	125396873869152 [label=PermuteBackward0]
	125396873869632 -> 125396873869152
	125396873869632 [label=ReluBackward0]
	125396873869440 -> 125396873869632
	125396873869440 [label=NativeBatchNormBackward0]
	125396873869728 -> 125396873869440
	125396873869728 [label=ConvolutionBackward0]
	125396873869920 -> 125396873869728
	125396873869920 [label=ReluBackward0]
	125396873870112 -> 125396873869920
	125396873870112 [label=NativeBatchNormBackward0]
	125396873870160 -> 125396873870112
	125396873870160 [label=ConvolutionBackward0]
	125396873870448 -> 125396873870160
	125396873870448 [label=PermuteBackward0]
	125396873870640 -> 125396873870448
	125396873870640 [label=CatBackward0]
	125396873870688 -> 125396873870640
	125396873870688 [label=PermuteBackward0]
	125396873870928 -> 125396873870688
	125396873870928 [label=MaxBackward0]
	125396873870976 -> 125396873870928
	125396873870976 [label=ReluBackward0]
	125396873871120 -> 125396873870976
	125396873871120 [label=NativeBatchNormBackward0]
	125396873871264 -> 125396873871120
	125396873871264 [label=ConvolutionBackward0]
	125396865974528 -> 125396873871264
	125396865974528 [label=ReluBackward0]
	125396865974720 -> 125396865974528
	125396865974720 [label=NativeBatchNormBackward0]
	125396865974768 -> 125396865974720
	125396865974768 [label=ConvolutionBackward0]
	125396865975056 -> 125396865974768
	125396865975056 [label=ReluBackward0]
	125396865975248 -> 125396865975056
	125396865975248 [label=NativeBatchNormBackward0]
	125396865975296 -> 125396865975248
	125396865975296 [label=ConvolutionBackward0]
	125396865975584 -> 125396865975296
	125396865975584 [label=PermuteBackward0]
	125396865975776 -> 125396865975584
	125396865975776 [label=CatBackward0]
	125396865975824 -> 125396865975776
	125396865975824 [label=IndexBackward0]
	125396865976016 -> 125396865975824
	125396865976016 [label=SliceBackward0]
	125396865976064 -> 125396865976016
	125396865976064 [label=PermuteBackward0]
	125396873867808 -> 125396865976064
	125396865975536 -> 125396865975296
	125397160407312 [label="point_base_model.sa2.mlp_convs.0.weight
 (64, 67, 1, 1)" fillcolor=lightblue]
	125397160407312 -> 125396865975536
	125396865975536 [label=AccumulateGrad]
	125396865975488 -> 125396865975296
	125397160407232 [label="point_base_model.sa2.mlp_convs.0.bias
 (64)" fillcolor=lightblue]
	125397160407232 -> 125396865975488
	125396865975488 [label=AccumulateGrad]
	125396865975152 -> 125396865975248
	125397160397392 [label="point_base_model.sa2.mlp_bns.0.weight
 (64)" fillcolor=lightblue]
	125397160397392 -> 125396865975152
	125396865975152 [label=AccumulateGrad]
	125396865975392 -> 125396865975248
	125397160397312 [label="point_base_model.sa2.mlp_bns.0.bias
 (64)" fillcolor=lightblue]
	125397160397312 -> 125396865975392
	125396865975392 [label=AccumulateGrad]
	125396865975008 -> 125396865974768
	125397160403712 [label="point_base_model.sa2.mlp_convs.1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	125397160403712 -> 125396865975008
	125396865975008 [label=AccumulateGrad]
	125396865974960 -> 125396865974768
	125397160429120 [label="point_base_model.sa2.mlp_convs.1.bias
 (64)" fillcolor=lightblue]
	125397160429120 -> 125396865974960
	125396865974960 [label=AccumulateGrad]
	125396865974624 -> 125396865974720
	125397160429040 [label="point_base_model.sa2.mlp_bns.1.weight
 (64)" fillcolor=lightblue]
	125397160429040 -> 125396865974624
	125396865974624 [label=AccumulateGrad]
	125396865974864 -> 125396865974720
	125397160428960 [label="point_base_model.sa2.mlp_bns.1.bias
 (64)" fillcolor=lightblue]
	125397160428960 -> 125396865974864
	125396865974864 [label=AccumulateGrad]
	125396865974480 -> 125396873871264
	125397160435200 [label="point_base_model.sa2.mlp_convs.2.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	125397160435200 -> 125396865974480
	125396865974480 [label=AccumulateGrad]
	125396865974432 -> 125396873871264
	125397160441840 [label="point_base_model.sa2.mlp_convs.2.bias
 (128)" fillcolor=lightblue]
	125397160441840 -> 125396865974432
	125396865974432 [label=AccumulateGrad]
	125396873871216 -> 125396873871120
	125397160441760 [label="point_base_model.sa2.mlp_bns.2.weight
 (128)" fillcolor=lightblue]
	125397160441760 -> 125396873871216
	125396873871216 [label=AccumulateGrad]
	125396865974336 -> 125396873871120
	125397160428880 [label="point_base_model.sa2.mlp_bns.2.bias
 (128)" fillcolor=lightblue]
	125397160428880 -> 125396865974336
	125396865974336 [label=AccumulateGrad]
	125396873870544 -> 125396873870640
	125396873870544 [label=SumBackward1]
	125396873871072 -> 125396873870544
	125396873871072 [label=MulBackward0]
	125396884203808 -> 125396873871072
	125396884203808 [label=IndexBackward0]
	125396865974672 -> 125396884203808
	125396865974672 [label=SliceBackward0]
	125396865975104 -> 125396865974672
	125396865975104 [label=PermuteBackward0]
	125396865975440 -> 125396865975104
	125396865975440 [label=ReluBackward0]
	125396865975728 -> 125396865975440
	125396865975728 [label=NativeBatchNormBackward0]
	125396865975968 -> 125396865975728
	125396865975968 [label=ConvolutionBackward0]
	125396865976304 -> 125396865975968
	125396865976304 [label=ReluBackward0]
	125396865976496 -> 125396865976304
	125396865976496 [label=NativeBatchNormBackward0]
	125396865976592 -> 125396865976496
	125396865976592 [label=ConvolutionBackward0]
	125396865976784 -> 125396865976592
	125396865976784 [label=PermuteBackward0]
	125396865976976 -> 125396865976784
	125396865976976 [label=CatBackward0]
	125396865977072 -> 125396865976976
	125396865977072 [label=PermuteBackward0]
	125396865977216 -> 125396865977072
	125396865977216 [label=MaxBackward0]
	125396865977312 -> 125396865977216
	125396865977312 [label=ReluBackward0]
	125396865977360 -> 125396865977312
	125396865977360 [label=NativeBatchNormBackward0]
	125396865977504 -> 125396865977360
	125396865977504 [label=ConvolutionBackward0]
	125396865977792 -> 125396865977504
	125396865977792 [label=ReluBackward0]
	125396865977984 -> 125396865977792
	125396865977984 [label=NativeBatchNormBackward0]
	125396865978032 -> 125396865977984
	125396865978032 [label=ConvolutionBackward0]
	125396865978320 -> 125396865978032
	125396865978320 [label=ReluBackward0]
	125396865978512 -> 125396865978320
	125396865978512 [label=NativeBatchNormBackward0]
	125396865978560 -> 125396865978512
	125396865978560 [label=ConvolutionBackward0]
	125396865978848 -> 125396865978560
	125396865978848 [label=PermuteBackward0]
	125396865979040 -> 125396865978848
	125396865979040 [label=CatBackward0]
	125396865979088 -> 125396865979040
	125396865979088 [label=IndexBackward0]
	125396865979280 -> 125396865979088
	125396865979280 [label=SliceBackward0]
	125396865979328 -> 125396865979280
	125396865979328 [label=PermuteBackward0]
	125396873870928 -> 125396865979328
	125396865978800 -> 125396865978560
	125397160428720 [label="point_base_model.sa3.mlp_convs.0.weight
 (128, 131, 1, 1)" fillcolor=lightblue]
	125397160428720 -> 125396865978800
	125396865978800 [label=AccumulateGrad]
	125396865978752 -> 125396865978560
	125397160428640 [label="point_base_model.sa3.mlp_convs.0.bias
 (128)" fillcolor=lightblue]
	125397160428640 -> 125396865978752
	125396865978752 [label=AccumulateGrad]
	125396865978416 -> 125396865978512
	125397160434960 [label="point_base_model.sa3.mlp_bns.0.weight
 (128)" fillcolor=lightblue]
	125397160434960 -> 125396865978416
	125396865978416 [label=AccumulateGrad]
	125396865978656 -> 125396865978512
	125397160434880 [label="point_base_model.sa3.mlp_bns.0.bias
 (128)" fillcolor=lightblue]
	125397160434880 -> 125396865978656
	125396865978656 [label=AccumulateGrad]
	125396865978272 -> 125396865978032
	125397160434800 [label="point_base_model.sa3.mlp_convs.1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	125397160434800 -> 125396865978272
	125396865978272 [label=AccumulateGrad]
	125396865978224 -> 125396865978032
	125397160434720 [label="point_base_model.sa3.mlp_convs.1.bias
 (128)" fillcolor=lightblue]
	125397160434720 -> 125396865978224
	125396865978224 [label=AccumulateGrad]
	125396865977888 -> 125396865977984
	125397160441360 [label="point_base_model.sa3.mlp_bns.1.weight
 (128)" fillcolor=lightblue]
	125397160441360 -> 125396865977888
	125396865977888 [label=AccumulateGrad]
	125396865978128 -> 125396865977984
	125397160441280 [label="point_base_model.sa3.mlp_bns.1.bias
 (128)" fillcolor=lightblue]
	125397160441280 -> 125396865978128
	125396865978128 [label=AccumulateGrad]
	125396865977744 -> 125396865977504
	125397160441120 [label="point_base_model.sa3.mlp_convs.2.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	125397160441120 -> 125396865977744
	125396865977744 [label=AccumulateGrad]
	125396865977696 -> 125396865977504
	125397160428240 [label="point_base_model.sa3.mlp_convs.2.bias
 (256)" fillcolor=lightblue]
	125397160428240 -> 125396865977696
	125396865977696 [label=AccumulateGrad]
	125396865977456 -> 125396865977360
	125397160428160 [label="point_base_model.sa3.mlp_bns.2.weight
 (256)" fillcolor=lightblue]
	125397160428160 -> 125396865977456
	125396865977456 [label=AccumulateGrad]
	125396865977600 -> 125396865977360
	125397160434480 [label="point_base_model.sa3.mlp_bns.2.bias
 (256)" fillcolor=lightblue]
	125397160434480 -> 125396865977600
	125396865977600 [label=AccumulateGrad]
	125396865977024 -> 125396865976976
	125396865977024 [label=SumBackward1]
	125396865977120 -> 125396865977024
	125396865977120 [label=MulBackward0]
	125396865978176 -> 125396865977120
	125396865978176 [label=IndexBackward0]
	125396865977840 -> 125396865978176
	125396865977840 [label=SliceBackward0]
	125396865978464 -> 125396865977840
	125396865978464 [label=PermuteBackward0]
	125396865978944 -> 125396865978464
	125396865978944 [label=MaxBackward0]
	125396865978896 -> 125396865978944
	125396865978896 [label=ReluBackward0]
	125396865979184 -> 125396865978896
	125396865979184 [label=NativeBatchNormBackward0]
	125396865979424 -> 125396865979184
	125396865979424 [label=ConvolutionBackward0]
	125396865979712 -> 125396865979424
	125396865979712 [label=ReluBackward0]
	125396865979904 -> 125396865979712
	125396865979904 [label=NativeBatchNormBackward0]
	125396865980000 -> 125396865979904
	125396865980000 [label=ConvolutionBackward0]
	125396865980192 -> 125396865980000
	125396865980192 [label=ReluBackward0]
	125396865980384 -> 125396865980192
	125396865980384 [label=NativeBatchNormBackward0]
	125396865980480 -> 125396865980384
	125396865980480 [label=ConvolutionBackward0]
	125396865980672 -> 125396865980480
	125396865980672 [label=PermuteBackward0]
	125396865980864 -> 125396865980672
	125396865980864 [label=CatBackward0]
	125396865980912 -> 125396865980864
	125396865980912 [label=IndexBackward0]
	125396865981104 -> 125396865980912
	125396865981104 [label=SliceBackward0]
	125396865981152 -> 125396865981104
	125396865981152 [label=PermuteBackward0]
	125396865977216 -> 125396865981152
	125396865980624 -> 125396865980480
	125397160428080 [label="point_base_model.sa4.mlp_convs.0.weight
 (256, 259, 1, 1)" fillcolor=lightblue]
	125397160428080 -> 125396865980624
	125396865980624 [label=AccumulateGrad]
	125396865980576 -> 125396865980480
	125397160428000 [label="point_base_model.sa4.mlp_convs.0.bias
 (256)" fillcolor=lightblue]
	125397160428000 -> 125396865980576
	125396865980576 [label=AccumulateGrad]
	125396865980432 -> 125396865980384
	125397160434320 [label="point_base_model.sa4.mlp_bns.0.weight
 (256)" fillcolor=lightblue]
	125397160434320 -> 125396865980432
	125396865980432 [label=AccumulateGrad]
	125396865980288 -> 125396865980384
	125397160434240 [label="point_base_model.sa4.mlp_bns.0.bias
 (256)" fillcolor=lightblue]
	125397160434240 -> 125396865980288
	125396865980288 [label=AccumulateGrad]
	125396865980144 -> 125396865980000
	125397160434000 [label="point_base_model.sa4.mlp_convs.1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	125397160434000 -> 125396865980144
	125396865980144 [label=AccumulateGrad]
	125396865980096 -> 125396865980000
	125397160433920 [label="point_base_model.sa4.mlp_convs.1.bias
 (256)" fillcolor=lightblue]
	125397160433920 -> 125396865980096
	125396865980096 [label=AccumulateGrad]
	125396865979952 -> 125396865979904
	125397160440880 [label="point_base_model.sa4.mlp_bns.1.weight
 (256)" fillcolor=lightblue]
	125397160440880 -> 125396865979952
	125396865979952 [label=AccumulateGrad]
	125396865979808 -> 125396865979904
	125397160440800 [label="point_base_model.sa4.mlp_bns.1.bias
 (256)" fillcolor=lightblue]
	125397160440800 -> 125396865979808
	125396865979808 [label=AccumulateGrad]
	125396865979664 -> 125396865979424
	125397160440480 [label="point_base_model.sa4.mlp_convs.2.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	125397160440480 -> 125396865979664
	125396865979664 [label=AccumulateGrad]
	125396865979616 -> 125396865979424
	125397160427600 [label="point_base_model.sa4.mlp_convs.2.bias
 (512)" fillcolor=lightblue]
	125397160427600 -> 125396865979616
	125396865979616 [label=AccumulateGrad]
	125396865979472 -> 125396865979184
	125397160433840 [label="point_base_model.sa4.mlp_bns.2.weight
 (512)" fillcolor=lightblue]
	125397160433840 -> 125396865979472
	125396865979472 [label=AccumulateGrad]
	125396865977168 -> 125396865979184
	125397160433760 [label="point_base_model.sa4.mlp_bns.2.bias
 (512)" fillcolor=lightblue]
	125397160433760 -> 125396865977168
	125396865977168 [label=AccumulateGrad]
	125396865976736 -> 125396865976592
	125397160433600 [label="point_base_model.fp4.mlp_convs.0.weight
 (256, 768, 1)" fillcolor=lightblue]
	125397160433600 -> 125396865976736
	125396865976736 [label=AccumulateGrad]
	125396865976688 -> 125396865976592
	125397160440240 [label="point_base_model.fp4.mlp_convs.0.bias
 (256)" fillcolor=lightblue]
	125397160440240 -> 125396865976688
	125396865976688 [label=AccumulateGrad]
	125396865976544 -> 125396865976496
	125397160440160 [label="point_base_model.fp4.mlp_bns.0.weight
 (256)" fillcolor=lightblue]
	125397160440160 -> 125396865976544
	125396865976544 [label=AccumulateGrad]
	125396865976400 -> 125396865976496
	125397160433520 [label="point_base_model.fp4.mlp_bns.0.bias
 (256)" fillcolor=lightblue]
	125397160433520 -> 125396865976400
	125396865976400 [label=AccumulateGrad]
	125396865976160 -> 125396865975968
	125397160433360 [label="point_base_model.fp4.mlp_convs.1.weight
 (256, 256, 1)" fillcolor=lightblue]
	125397160433360 -> 125396865976160
	125396865976160 [label=AccumulateGrad]
	125396865976208 -> 125396865975968
	125397160433280 [label="point_base_model.fp4.mlp_convs.1.bias
 (256)" fillcolor=lightblue]
	125397160433280 -> 125396865976208
	125396865976208 [label=AccumulateGrad]
	125396865975680 -> 125396865975728
	125397160439920 [label="point_base_model.fp4.mlp_bns.1.weight
 (256)" fillcolor=lightblue]
	125397160439920 -> 125396865975680
	125396865975680 [label=AccumulateGrad]
	125396865974384 -> 125396865975728
	125397160439840 [label="point_base_model.fp4.mlp_bns.1.bias
 (256)" fillcolor=lightblue]
	125397160439840 -> 125396865974384
	125396865974384 [label=AccumulateGrad]
	125396873870400 -> 125396873870160
	125397160433040 [label="point_base_model.fp3.mlp_convs.0.weight
 (256, 384, 1)" fillcolor=lightblue]
	125397160433040 -> 125396873870400
	125396873870400 [label=AccumulateGrad]
	125396873870352 -> 125396873870160
	125397160432960 [label="point_base_model.fp3.mlp_convs.0.bias
 (256)" fillcolor=lightblue]
	125397160432960 -> 125396873870352
	125396873870352 [label=AccumulateGrad]
	125396873870016 -> 125396873870112
	125397160439600 [label="point_base_model.fp3.mlp_bns.0.weight
 (256)" fillcolor=lightblue]
	125397160439600 -> 125396873870016
	125396873870016 [label=AccumulateGrad]
	125396873870256 -> 125396873870112
	125397160439520 [label="point_base_model.fp3.mlp_bns.0.bias
 (256)" fillcolor=lightblue]
	125397160439520 -> 125396873870256
	125396873870256 [label=AccumulateGrad]
	125396873869872 -> 125396873869728
	125397160432720 [label="point_base_model.fp3.mlp_convs.1.weight
 (256, 256, 1)" fillcolor=lightblue]
	125397160432720 -> 125396873869872
	125396873869872 [label=AccumulateGrad]
	125396873869824 -> 125396873869728
	125397160432640 [label="point_base_model.fp3.mlp_convs.1.bias
 (256)" fillcolor=lightblue]
	125397160432640 -> 125396873869824
	125396873869824 [label=AccumulateGrad]
	125396873869680 -> 125396873869440
	125397160439280 [label="point_base_model.fp3.mlp_bns.1.weight
 (256)" fillcolor=lightblue]
	125397160439280 -> 125396873869680
	125396873869680 [label=AccumulateGrad]
	125396873867760 -> 125396873869440
	125397160439200 [label="point_base_model.fp3.mlp_bns.1.bias
 (256)" fillcolor=lightblue]
	125397160439200 -> 125396873867760
	125396873867760 [label=AccumulateGrad]
	125396873867328 -> 125396873867088
	125397160432400 [label="point_base_model.fp2.mlp_convs.0.weight
 (256, 320, 1)" fillcolor=lightblue]
	125397160432400 -> 125396873867328
	125396873867328 [label=AccumulateGrad]
	125396873867280 -> 125396873867088
	125397160432320 [label="point_base_model.fp2.mlp_convs.0.bias
 (256)" fillcolor=lightblue]
	125397160432320 -> 125396873867280
	125396873867280 [label=AccumulateGrad]
	125396873866992 -> 125396873867040
	125397160438960 [label="point_base_model.fp2.mlp_bns.0.weight
 (256)" fillcolor=lightblue]
	125397160438960 -> 125396873866992
	125396873866992 [label=AccumulateGrad]
	125396873867184 -> 125396873867040
	125397160438880 [label="point_base_model.fp2.mlp_bns.0.bias
 (256)" fillcolor=lightblue]
	125397160438880 -> 125396873867184
	125396873867184 [label=AccumulateGrad]
	125396873866896 -> 125396873866656
	125397160432080 [label="point_base_model.fp2.mlp_convs.1.weight
 (128, 256, 1)" fillcolor=lightblue]
	125397160432080 -> 125396873866896
	125396873866896 [label=AccumulateGrad]
	125396873866848 -> 125396873866656
	125397160432000 [label="point_base_model.fp2.mlp_convs.1.bias
 (128)" fillcolor=lightblue]
	125397160432000 -> 125396873866848
	125396873866848 [label=AccumulateGrad]
	125396873866608 -> 125396873866512
	125397160438480 [label="point_base_model.fp2.mlp_bns.1.weight
 (128)" fillcolor=lightblue]
	125397160438480 -> 125396873866608
	125396873866608 [label=AccumulateGrad]
	125396873866752 -> 125396873866512
	125397160438400 [label="point_base_model.fp2.mlp_bns.1.bias
 (128)" fillcolor=lightblue]
	125397160438400 -> 125396873866752
	125396873866752 [label=AccumulateGrad]
	125396873865840 -> 125396873865696
	125397160431920 [label="point_base_model.fp1.mlp_convs.0.weight
 (128, 128, 1)" fillcolor=lightblue]
	125397160431920 -> 125396873865840
	125396873865840 [label=AccumulateGrad]
	125396873865792 -> 125396873865696
	125397160431840 [label="point_base_model.fp1.mlp_convs.0.bias
 (128)" fillcolor=lightblue]
	125397160431840 -> 125396873865792
	125396873865792 [label=AccumulateGrad]
	125396873865648 -> 125396873865600
	125397160438320 [label="point_base_model.fp1.mlp_bns.0.weight
 (128)" fillcolor=lightblue]
	125397160438320 -> 125396873865648
	125396873865648 [label=AccumulateGrad]
	125396873865504 -> 125396873865600
	125397160438240 [label="point_base_model.fp1.mlp_bns.0.bias
 (128)" fillcolor=lightblue]
	125397160438240 -> 125396873865504
	125396873865504 [label=AccumulateGrad]
	125396873865408 -> 125396873865312
	125397160431440 [label="point_base_model.fp1.mlp_convs.1.weight
 (128, 128, 1)" fillcolor=lightblue]
	125397160431440 -> 125396873865408
	125396873865408 [label=AccumulateGrad]
	125396873865360 -> 125396873865312
	125397160431360 [label="point_base_model.fp1.mlp_convs.1.bias
 (128)" fillcolor=lightblue]
	125397160431360 -> 125396873865360
	125396873865360 [label=AccumulateGrad]
	125396873865264 -> 125396873865216
	125397160438000 [label="point_base_model.fp1.mlp_bns.1.weight
 (128)" fillcolor=lightblue]
	125397160438000 -> 125396873865264
	125396873865264 [label=AccumulateGrad]
	125396873855136 -> 125396873865216
	125397160437920 [label="point_base_model.fp1.mlp_bns.1.bias
 (128)" fillcolor=lightblue]
	125397160437920 -> 125396873855136
	125396873855136 [label=AccumulateGrad]
	125396873855280 -> 125396904160768
	125397160431120 [label="point_base_model.fp1.mlp_convs.2.weight
 (128, 128, 1)" fillcolor=lightblue]
	125397160431120 -> 125396873855280
	125396873855280 [label=AccumulateGrad]
	125396873865024 -> 125396904160768
	125397160431040 [label="point_base_model.fp1.mlp_convs.2.bias
 (128)" fillcolor=lightblue]
	125397160431040 -> 125396873865024
	125396873865024 [label=AccumulateGrad]
	125396873864784 -> 125396878649872
	125397160437520 [label="point_base_model.fp1.mlp_bns.2.weight
 (128)" fillcolor=lightblue]
	125397160437520 -> 125396873864784
	125396873864784 [label=AccumulateGrad]
	125396873864880 -> 125396878649872
	125397160437440 [label="point_base_model.fp1.mlp_bns.2.bias
 (128)" fillcolor=lightblue]
	125397160437440 -> 125396873864880
	125396873864880 [label=AccumulateGrad]
	125396878650112 -> 125396891041600
	125397160410112 [label="fc_0.weight
 (256, 128, 1)" fillcolor=lightblue]
	125397160410112 -> 125396878650112
	125396878650112 [label=AccumulateGrad]
	125396878650064 -> 125396891041600
	125397160410032 [label="fc_0.bias
 (256)" fillcolor=lightblue]
	125397160410032 -> 125396878650064
	125396878650064 [label=AccumulateGrad]
	125396927892208 -> 125396903871392
	125397160409952 [label="fc_1.weight
 (128, 256, 1)" fillcolor=lightblue]
	125397160409952 -> 125396927892208
	125396927892208 [label=AccumulateGrad]
	125396884204048 -> 125396903871392
	125397160409872 [label="fc_1.bias
 (128)" fillcolor=lightblue]
	125397160409872 -> 125396884204048
	125396884204048 [label=AccumulateGrad]
	125396905345280 -> 125396879102480
	125397160409792 [label="fc_out.weight
 (2, 128, 1)" fillcolor=lightblue]
	125397160409792 -> 125396905345280
	125396905345280 [label=AccumulateGrad]
	125396884343152 -> 125396879102480
	125397160409712 [label="fc_out.bias
 (2)" fillcolor=lightblue]
	125397160409712 -> 125396884343152
	125396884343152 [label=AccumulateGrad]
	125396891717728 -> 125396873854352
}
